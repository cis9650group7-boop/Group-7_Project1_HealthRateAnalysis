{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cis9650group7-boop/Group-7_Project1_HealthRateAnalysis/blob/dev/term_project_group7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Project 1: Analysis of Health Rate"
      ],
      "metadata": {
        "id": "B3aIe1AWf1FL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "XGP6kl5g7bX3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5d58028-4c8a-41a8-fb5d-833eefae8777"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "SUWyEn2xqn5W"
      },
      "cell_type": "markdown",
      "source": [
        "### Author: CIS 9650 Group 7 (Anish Bijusoman, Ivana Sundararao, Qingrong Tan, Reem Hussein)\n",
        "### Date : November 28th, 2025"
      ]
    },
    {
      "metadata": {
        "id": "vkBCfM4xqn5X"
      },
      "cell_type": "markdown",
      "source": [
        "## Executive Summary"
      ]
    },
    {
      "metadata": {
        "id": "nl7x4ox0qn5X"
      },
      "cell_type": "markdown",
      "source": []
    },
    {
      "metadata": {
        "id": "NQ3WFyKOqn5X"
      },
      "cell_type": "markdown",
      "source": [
        "## Table of Contents"
      ]
    },
    {
      "metadata": {
        "id": "XQlzOorTqn5X"
      },
      "cell_type": "markdown",
      "source": [
        "1. Introduction\n",
        "2. Problem Statement / Research Question\n",
        "3. Data Description\n",
        "4. Setup and Environment\n",
        "5. Data Loading\n",
        "6. Data Preparation\n",
        "7. Model Planning\n",
        "8. Model Building / Analysis\n",
        "9. Discussion & Interpretation\n",
        "10. Conclusion\n",
        "11. References\n",
        "12. Appendix"
      ]
    },
    {
      "metadata": {
        "id": "h6FSAiEmqn5Y"
      },
      "cell_type": "markdown",
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yAlW921_rRvk"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction"
      ],
      "metadata": {
        "id": "rNHFUNoMrZkD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem Statement / Research Question"
      ],
      "metadata": {
        "id": "gxlnArrBrm4I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Description"
      ],
      "metadata": {
        "id": "0C3kZi5HrrSk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup and Environment"
      ],
      "metadata": {
        "id": "PV0iyLXurt7q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-cloud-storage"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mElIRgqfvDNX",
        "outputId": "63ed2a83-9942-4128-81e3-27172e8adba7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.12/dist-packages (3.6.0)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.26.1 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage) (2.43.0)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=2.27.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage) (2.28.1)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0,>=2.4.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage) (2.5.0)\n",
            "Requirement already satisfied: google-resumable-media<3.0.0,>=2.7.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage) (2.8.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.22.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage) (2.32.4)\n",
            "Requirement already satisfied: google-crc32c<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage) (1.7.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3.0.0,>=2.27.0->google-cloud-storage) (1.72.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3.0.0,>=2.27.0->google-cloud-storage) (5.29.5)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3.0.0,>=2.27.0->google-cloud-storage) (1.26.1)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.26.1->google-cloud-storage) (6.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.26.1->google-cloud-storage) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.26.1->google-cloud-storage) (4.9.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.22.0->google-cloud-storage) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.22.0->google-cloud-storage) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.22.0->google-cloud-storage) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.22.0->google-cloud-storage) (2025.11.12)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.26.1->google-cloud-storage) (0.6.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import json\n",
        "import os\n",
        "from google.cloud import storage\n",
        "from io import BytesIO"
      ],
      "metadata": {
        "id": "Wd4ItUpruFe2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Loading"
      ],
      "metadata": {
        "id": "DMi7uYUhrx0F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Functions"
      ],
      "metadata": {
        "id": "kdcxnKu7vqbS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import storage\n",
        "import pandas as pd\n",
        "from io import BytesIO\n",
        "import os\n",
        "import json\n",
        "import requests\n",
        "import re # Import regex module for parsing HTML\n",
        "\n",
        "def list_public_bucket(bucket_name, course, project):\n",
        "    prefix = f\"{course}/Project {project}/\"\n",
        "\n",
        "    client = storage.Client.create_anonymous_client()\n",
        "    bucket = client.bucket(bucket_name)\n",
        "    blobs = client.list_blobs(bucket, prefix=prefix)\n",
        "    print(f\"Listing files in public bucket '{bucket_name}' under '{prefix}':\")\n",
        "    filenames = []\n",
        "    for blob in blobs:\n",
        "        print(blob.name)\n",
        "        filenames.append(blob.name)\n",
        "\n",
        "    return filenames\n",
        "\n",
        "def gdrive_file_to_dataframe(file_id: str, file_type: str):\n",
        "    \"\"\"\n",
        "    Downloads a file from Google Drive using its ID and returns a pandas DataFrame.\n",
        "    Handles Google Drive virus scan warnings by parsing the HTML form to get the\n",
        "    actual download URL.\n",
        "    \"\"\"\n",
        "    URL = \"https://docs.google.com/uc?export=download\"\n",
        "\n",
        "    session = requests.Session()\n",
        "    response = session.get(URL, params={'id': file_id}, stream=True)\n",
        "    response.raise_for_status() # Raise an HTTPError for bad responses (4xx or 5xx)\n",
        "\n",
        "    # Check if the response content is the virus scan warning HTML page\n",
        "    if \"Google Drive - Virus scan warning\" in response.text:\n",
        "        print(\"Google Drive virus scan warning detected. Attempting to bypass...\")\n",
        "        # Extract the download action URL and hidden input parameters from the HTML form\n",
        "        match = re.search(r'<form id=\"download-form\" action=\"([^\"]+)\" method=\"get\">', response.text)\n",
        "        if not match:\n",
        "            raise ValueError(\"Could not find download form in virus warning page.\")\n",
        "        download_action_url = match.group(1)\n",
        "\n",
        "        hidden_inputs = re.findall(r'<input type=\"hidden\" name=\"([^\"]+)\" value=\"([^\"]*)\">', response.text)\n",
        "        download_params = {name: value for name, value in hidden_inputs}\n",
        "\n",
        "        # Make the actual download request with the extracted parameters\n",
        "        final_response = session.get(download_action_url, params=download_params, stream=True)\n",
        "        final_response.raise_for_status()\n",
        "        data = BytesIO(final_response.content)\n",
        "    else:\n",
        "        # No virus warning, proceed with the initial response content\n",
        "        data = BytesIO(response.content)\n",
        "\n",
        "    df = None\n",
        "    if file_type == \"csv\":\n",
        "        df = pd.read_csv(data, engine='python', on_bad_lines='warn')\n",
        "    elif file_type in [\"xls\", \"xlsx\"]:\n",
        "        df = pd.read_excel(data)\n",
        "    elif file_type == \"parquet\":\n",
        "        df = pd.read_parquet(data)\n",
        "    elif file_type == \"json\":\n",
        "        text = data.read().decode(\"utf-8\")\n",
        "        json_obj = json.loads(text)\n",
        "        if isinstance(json_obj, list):\n",
        "            df = pd.DataFrame(json_obj)\n",
        "        elif isinstance(json_obj, dict):\n",
        "            df = pd.json_normalize(json_obj)\n",
        "        else:\n",
        "            raise ValueError(\"Unsupported JSON structure\")\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported file type: {file_type}\")\n",
        "\n",
        "    return df\n",
        "\n",
        "# Fetching the data from the provided Google Drive link\n",
        "try:\n",
        "    file_id_to_fetch = '1yJjVih68D_J4JON2LXMLGIh_FoeibwaG'\n",
        "    # Assuming the file type is CSV based on the filename provided\n",
        "    gdrive_df = gdrive_file_to_dataframe(file_id_to_fetch, 'csv')\n",
        "    print(\"Successfully fetched and loaded data from Google Drive into 'gdrive_df'. Head of the DataFrame:\")\n",
        "    print(gdrive_df.head())\n",
        "except Exception as e:\n",
        "    print(f\"Error fetching or loading data from Google Drive: {e}\")\n"
      ],
      "metadata": {
        "id": "1Wc3fjEBuFAz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b429b81-c3b7-472b-9726-ecf5757f957d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Google Drive virus scan warning detected. Attempting to bypass...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation"
      ],
      "metadata": {
        "id": "Q9toqCgWr0Op"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = gdrive_df\n",
        "\n",
        "print(\"Number of rows\", len(df))\n",
        "print(\"Number of columns\", len(df.columns))"
      ],
      "metadata": {
        "id": "eqLc8hNqrYxv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# datatypes available\n",
        "print(\"The datatypes available are:\")\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)\n",
        "print(df.dtypes)"
      ],
      "metadata": {
        "id": "edmnmaL5uEmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# similar naming columns\n",
        "pd.set_option('display.max_columns', None)\n",
        "df.columns = df.columns.str.lower().str.replace('_', '')\n",
        "\n",
        "list_cols= list(df.columns)\n",
        "print(\"The columns are:\")\n",
        "print(list_cols)"
      ],
      "metadata": {
        "id": "0sFvdjTHijaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These need not be changed:'id', 'slug', 'created', 'modified', 'id', 'faceturl', 'fullname', 'fullnamespecialty'"
      ],
      "metadata": {
        "id": "PRaUAi8fjRIq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Method 1: Feature engineering"
      ],
      "metadata": {
        "id": "8iPJOWt4PJae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select usable columns\n",
        "cols_to_keep = [\"_id\", \"full_name\", \"specialty_name\", \"location.city.name\",\"rating.average\", \"rating.helpfulness\", \"rating.punctuality\",\"rating.staff\", \"rating.count\"]\n",
        "\n",
        "df_clean = df[cols_to_keep].copy()\n",
        "\n",
        "# Rename columns to simpler names\n",
        "df_clean = df_clean.rename(columns={\n",
        "    \"location.city.name\": \"city\",\n",
        "    \"rating.average\": \"rating_avg\",\n",
        "    \"rating.helpfulness\": \"rating_help\",\n",
        "    \"rating.punctuality\": \"rating_punctuality\",\n",
        "    \"rating.staff\": \"rating_staff\",\n",
        "    \"rating.count\": \"rating_count\"\n",
        "})\n",
        "\n",
        "# Convert numeric columns to proper numeric types\n",
        "numeric_cols = [\n",
        "    \"rating_avg\", \"rating_help\", \"rating_punctuality\",\n",
        "    \"rating_staff\", \"rating_count\"\n",
        "]\n",
        "\n",
        "for col in numeric_cols:\n",
        "    df_clean[col] = pd.to_numeric(df_clean[col], errors=\"coerce\")\n",
        "\n",
        "# Drop rows with no rating information\n",
        "df_clean = df_clean.dropna(subset=[\"rating_avg\"])\n",
        "\n",
        "# Before having this the rating avg and rating_help was 0's\n",
        "df_clean = df_clean[df_clean[\"rating_count\"] > 0]\n",
        "df_clean = df_clean[df_clean[\"rating_avg\"] > 0]\n",
        "\n",
        "# Reset index\n",
        "df_clean = df_clean.reset_index(drop=True)\n",
        "\n",
        "df_clean.head() # this is to see the clean data"
      ],
      "metadata": {
        "id": "-upnmg83MW-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Method 2: Feature engineering"
      ],
      "metadata": {
        "id": "OdknHwF3PSXI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most columns share prefixes like:\n",
        "location.*\n",
        "images.*\n",
        "rating.*\n",
        "doctorlocations[n].*\n",
        "doctorlocationhours[n].*\n",
        "\n",
        "We can automatically group these"
      ],
      "metadata": {
        "id": "F3hkAf8ZPam6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def group_columns_by_prefix(df, sep='.'):\n",
        "    groups = {}\n",
        "    for col in df.columns:\n",
        "        prefix = col.split(sep)[0]\n",
        "        groups.setdefault(prefix, []).append(col)\n",
        "    return groups\n",
        "\n",
        "groups = group_columns_by_prefix(df)\n",
        "for g, cols in groups.items():\n",
        "    print(g, len(cols))\n"
      ],
      "metadata": {
        "id": "g7_QjwxfPRgu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will Collapse Deeply Nested Repeating Blocks"
      ],
      "metadata": {
        "id": "Tb5tY_J2P2MH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "pattern = re.compile(r\"doctor_locations\\[(\\d+)\\]\\.(.+)\")\n",
        "\n",
        "grouped = {}\n",
        "\n",
        "for col in df.columns:\n",
        "    m = pattern.match(col)\n",
        "    if m:\n",
        "        idx = int(m.group(1))\n",
        "        field = m.group(2)\n",
        "        grouped.setdefault(idx, {})[field] = col\n",
        "\n",
        "print({k: len(v) for k, v in grouped.items()})\n"
      ],
      "metadata": {
        "id": "AfYq0HusP302"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the nested objects\n",
        "dl_cols = [c for c in df.columns if c.startswith(\"doctor_locations[\")]\n",
        "doctor_df = df[dl_cols].copy()\n"
      ],
      "metadata": {
        "id": "-Q14MY2xR3GX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop the original wide columns\n",
        "df = df.drop(columns=[c for c in df.columns if c.startswith(\"doctor_locations[\")])"
      ],
      "metadata": {
        "id": "dxR9NUDxUEZ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Removing Unnecessary Metadata Columns"
      ],
      "metadata": {
        "id": "OfSxZdPEQd87"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cols_to_drop = df.filter(regex=\"created|modified|slug|deleted|image|url$\").columns\n",
        "df = df.drop(columns=cols_to_drop)\n"
      ],
      "metadata": {
        "id": "eeGIMCD0QdtX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Planning"
      ],
      "metadata": {
        "id": "2LakOsEXr3lT"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6OppN2NguEMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Vl5RPihiuD9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model building / Analysis"
      ],
      "metadata": {
        "id": "4CjKZrjUr5jE"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cOzrfMmPuDTf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hRdii9o7uCw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Discussion and Results"
      ],
      "metadata": {
        "id": "Fw_hs8cur9ep"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "fMIDNj9YuAbo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion"
      ],
      "metadata": {
        "id": "fstKat9EsCOz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "9_S9Jo3tt9y3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## References"
      ],
      "metadata": {
        "id": "wN9Uya8asFaR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Barber, David. Bayesian Reasoning and Machine Learning. Cambridge University Press, 2012.\n",
        "2. Aste, Tomaso, Paola Cerchiello, and Roberta Scaramozzino. \"Information-Theoretic Causality Detection between Financial and Sentiment Data.\"Entropy, vol. 24, no. 6, 2022, pp. 1–18. DOI:10.3390/e24060774.\n",
        "3. Metz, Cade. \"Microsoft Puts OpenAI’s Sam Altman in Charge of New Advanced AI Research Team.\"\n",
        "The New York Times, 20 Nov. 2023, www.nytimes.com/2023/11/20/technology/openai-microsoft-altman.html"
      ],
      "metadata": {
        "id": "iqLZY_rAt-TW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Appendix"
      ],
      "metadata": {
        "id": "ZT5TPWb9sHws"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vIxXm5Dlt_Uf"
      }
    }
  ]
}