{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cis9650group7-boop/Group-7_Project1_HealthRateAnalysis/blob/main/term_project_group7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Project 1: Analysis of Health Rate"
      ],
      "metadata": {
        "id": "B3aIe1AWf1FL"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KlZ2o4ByS2Z-"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "XGP6kl5g7bX3",
        "outputId": "3124360a-f83d-47a8-8dac-cfbfea00268d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1408506528.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    132\u001b[0m   )\n\u001b[1;32m    133\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "SUWyEn2xqn5W"
      },
      "cell_type": "markdown",
      "source": [
        "### Author: CIS 9650 Group 7 (Anish Bijusoman, Ivana Sundararao, Qingrong Tan, Reem Hussein)\n",
        "### Date : November 28th, 2025"
      ]
    },
    {
      "metadata": {
        "id": "vkBCfM4xqn5X"
      },
      "cell_type": "markdown",
      "source": [
        "## Executive Summary"
      ]
    },
    {
      "metadata": {
        "id": "nl7x4ox0qn5X"
      },
      "cell_type": "markdown",
      "source": []
    },
    {
      "metadata": {
        "id": "NQ3WFyKOqn5X"
      },
      "cell_type": "markdown",
      "source": [
        "## Table of Contents"
      ]
    },
    {
      "metadata": {
        "id": "XQlzOorTqn5X"
      },
      "cell_type": "markdown",
      "source": [
        "1. Introduction\n",
        "2. Problem Statement / Research Question\n",
        "3. Data Description\n",
        "4. Setup and Environment\n",
        "5. Data Loading\n",
        "6. Data Preparation\n",
        "7. Model Planning\n",
        "8. Model Building / Analysis\n",
        "9. Discussion & Interpretation\n",
        "10. Conclusion\n",
        "11. References\n",
        "12. Appendix"
      ]
    },
    {
      "metadata": {
        "id": "h6FSAiEmqn5Y"
      },
      "cell_type": "markdown",
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yAlW921_rRvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction"
      ],
      "metadata": {
        "id": "rNHFUNoMrZkD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem Statement / Research Question"
      ],
      "metadata": {
        "id": "gxlnArrBrm4I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Description"
      ],
      "metadata": {
        "id": "0C3kZi5HrrSk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup and Environment"
      ],
      "metadata": {
        "id": "PV0iyLXurt7q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-cloud-storage"
      ],
      "metadata": {
        "id": "mElIRgqfvDNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import json\n",
        "import os\n",
        "from google.cloud import storage\n",
        "from io import BytesIO"
      ],
      "metadata": {
        "id": "Wd4ItUpruFe2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Loading"
      ],
      "metadata": {
        "id": "DMi7uYUhrx0F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Functions"
      ],
      "metadata": {
        "id": "kdcxnKu7vqbS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import storage\n",
        "\n",
        "def list_public_bucket(bucket_name, course, project):\n",
        "    prefix = f\"{course}/Project {project}/\"\n",
        "\n",
        "    client = storage.Client.create_anonymous_client()\n",
        "    bucket = client.bucket(bucket_name)\n",
        "    blobs = client.list_blobs(bucket, prefix=prefix)\n",
        "    print(f\"Listing files in public bucket '{bucket_name}' under '{prefix}':\")\n",
        "    filenames = []\n",
        "    for blob in blobs:\n",
        "        print(blob.name)\n",
        "        filenames.append(blob.name)\n",
        "\n",
        "    return filenames"
      ],
      "metadata": {
        "id": "1Wc3fjEBuFAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import storage\n",
        "import pandas as pd\n",
        "from io import BytesIO\n",
        "import os\n",
        "import json\n",
        "\n",
        "def gcs_file_to_dataframe(bucket_name: str, blob_path: str, use_cols:list):\n",
        "\n",
        "    # Anonymous client for public buckets\n",
        "    client = storage.Client.create_anonymous_client()\n",
        "    bucket = client.bucket(bucket_name)\n",
        "    blob = bucket.blob(blob_path)\n",
        "\n",
        "    # Download file content as bytes\n",
        "    data = blob.download_as_bytes()\n",
        "\n",
        "    # Only read columns we use\n",
        "    df = pd.read_csv(BytesIO(data),usecols = use_cols)\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "LPDXmA5cx5lm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set bucket parameters for \"msba-online-data/CIS9650/Project 01\"\n",
        "BUCKET_NAME = \"msba-online-data\"\n",
        "PROJECT_NUMBER = \"01\"\n",
        "COURSE = \"CIS9650\"\n",
        "healthrate_raw = list_public_bucket(BUCKET_NAME,COURSE,PROJECT_NUMBER)"
      ],
      "metadata": {
        "id": "6Vu5zWyRv1YO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the csv file into a Pandas dataframe\n",
        "\n",
        "columns_analysis = ['_id',\n",
        "    'specialty_name',\n",
        "    'rating.average',\n",
        "    'rating.count']\n",
        "\n",
        "csv_path = healthrate_raw[1]\n",
        "df = gcs_file_to_dataframe(BUCKET_NAME,  csv_path, columns_analysis)\n",
        "\n",
        "print(df.head())\n",
        "print(f'length:{len(df)}')\n"
      ],
      "metadata": {
        "id": "8ZzYd5BPxEeZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-11-24T22:02:44.170067Z",
          "start_time": "2025-11-24T22:02:44.159297Z"
        },
        "id": "sIah83YVpkvr"
      },
      "cell_type": "code",
      "source": [
        "df_expanded = df.explode(\"details\", ignore_index=True)\n",
        "\n",
        "# 2. Convert the dict into columns\n",
        "detail_cols = df_expanded[\"rows\"].apply(pd.Series)\n",
        "\n",
        "# 3. Merge back and drop the dict column\n",
        "df_flat = pd.concat([df_expanded.drop(columns=[\"rows\"]), detail_cols], axis=1)\n",
        "\n",
        "df_flat"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation"
      ],
      "metadata": {
        "id": "Q9toqCgWr0Op"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The raw data set from the CSV file contained 1,611 columns and 143,791 rows. That in itself is too much to analyze, and also contained fields such as images, phone numbers, etc... Field that would be irrelivant to our analysis, and research question. So this calls for some data cleaning!\n",
        "\n",
        "* We selected a focused subset of 9 relevant variables that describe each doctor’s name, specialty, city, and core rating metrics.\n",
        "\n",
        "* We renamed the columns to simpler names. Column names were written such as \"location.city.name\", \"rating.average\" so we changed them to \"city\" and \"rating_average\"\n",
        "\n",
        "* Rating fields were stored as mixed text/numeric types so we converted the rating columns to numeric using pd.to_numeric(df_clean[col], errors=\"coerce\")\n",
        "\n",
        "* We filtered out zero rating doctors to make sure we only analyze doctors who have actual patient reviews in order to produce valid insights\n",
        "\n",
        "* After filtering, we reset the index for smooth readability"
      ],
      "metadata": {
        "id": "1BEkANPrToIm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- DATA CLEANING ----------\n",
        "# Select usable columns\n",
        "cols_to_keep = [\n",
        "    \"_id\", \"full_name\", \"specialty_name\", \"location.city.name\",\n",
        "    \"rating.average\", \"rating.helpfulness\", \"rating.punctuality\",\n",
        "    \"rating.staff\", \"rating.count\"\n",
        "]\n",
        "\n",
        "df_clean = df[cols_to_keep].copy()\n",
        "\n",
        "# Rename columns to simpler names\n",
        "df_clean = df_clean.rename(columns={\n",
        "    \"location.city.name\": \"city\",\n",
        "    \"rating.average\": \"rating_avg\",\n",
        "    \"rating.helpfulness\": \"rating_help\",\n",
        "    \"rating.punctuality\": \"rating_punctuality\",\n",
        "    \"rating.staff\": \"rating_staff\",\n",
        "    \"rating.count\": \"rating_count\"\n",
        "})\n",
        "\n",
        "# Convert numeric columns to proper numeric types\n",
        "numeric_cols = [\n",
        "    \"rating_avg\", \"rating_help\", \"rating_punctuality\",\n",
        "    \"rating_staff\", \"rating_count\"\n",
        "]\n",
        "\n",
        "for col in numeric_cols:\n",
        "    df_clean[col] = pd.to_numeric(df_clean[col], errors=\"coerce\")\n",
        "\n",
        "# Drop rows with no rating information\n",
        "df_clean = df_clean.dropna(subset=[\"rating_avg\"])\n",
        "\n",
        "# Before having this the rating avg and rating_help was 0's\n",
        "df_clean = df_clean[df_clean[\"rating_count\"] > 0]\n",
        "df_clean = df_clean[df_clean[\"rating_avg\"] > 0]\n",
        "\n",
        "# Reset index\n",
        "df_clean = df_clean.reset_index(drop=True)\n",
        "\n",
        "df_clean.head() # this is to see the clean data"
      ],
      "metadata": {
        "id": "gU4ifI7ATUbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(50) # this is unclean data"
      ],
      "metadata": {
        "id": "edmnmaL5uEmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Planning"
      ],
      "metadata": {
        "id": "2LakOsEXr3lT"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6OppN2NguEMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Vl5RPihiuD9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model building / Analysis"
      ],
      "metadata": {
        "id": "4CjKZrjUr5jE"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cOzrfMmPuDTf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hRdii9o7uCw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Discussion and Results"
      ],
      "metadata": {
        "id": "Fw_hs8cur9ep"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "fMIDNj9YuAbo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion"
      ],
      "metadata": {
        "id": "fstKat9EsCOz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "9_S9Jo3tt9y3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## References"
      ],
      "metadata": {
        "id": "wN9Uya8asFaR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Barber, David. Bayesian Reasoning and Machine Learning. Cambridge University Press, 2012.\n",
        "2. Aste, Tomaso, Paola Cerchiello, and Roberta Scaramozzino. \"Information-Theoretic Causality Detection between Financial and Sentiment Data.\"Entropy, vol. 24, no. 6, 2022, pp. 1–18. DOI:10.3390/e24060774.\n",
        "3. Metz, Cade. \"Microsoft Puts OpenAI’s Sam Altman in Charge of New Advanced AI Research Team.\"\n",
        "The New York Times, 20 Nov. 2023, www.nytimes.com/2023/11/20/technology/openai-microsoft-altman.html"
      ],
      "metadata": {
        "id": "iqLZY_rAt-TW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Appendix"
      ],
      "metadata": {
        "id": "ZT5TPWb9sHws"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vIxXm5Dlt_Uf"
      }
    }
  ]
}