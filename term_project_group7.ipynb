{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cis9650group7-boop/Group-7_Project1_HealthRateAnalysis/blob/dev/term_project_group7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Project 1: Analysis of Health Rate"
      ],
      "metadata": {
        "id": "B3aIe1AWf1FL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "XGP6kl5g7bX3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9279bd1-4cc8-45da-aec5-50f3a30bc08a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "SUWyEn2xqn5W"
      },
      "cell_type": "markdown",
      "source": [
        "### Author: CIS 9650 Group 7 (Anish Bijusoman, Ivana Sundararao, Qingrong Tan, Reem Hussein)\n",
        "### Date : November 28th, 2025"
      ]
    },
    {
      "metadata": {
        "id": "vkBCfM4xqn5X"
      },
      "cell_type": "markdown",
      "source": [
        "## Executive Summary"
      ]
    },
    {
      "metadata": {
        "id": "nl7x4ox0qn5X"
      },
      "cell_type": "markdown",
      "source": []
    },
    {
      "metadata": {
        "id": "NQ3WFyKOqn5X"
      },
      "cell_type": "markdown",
      "source": [
        "## Table of Contents"
      ]
    },
    {
      "metadata": {
        "id": "XQlzOorTqn5X"
      },
      "cell_type": "markdown",
      "source": [
        "1. Introduction\n",
        "2. Problem Statement / Research Question\n",
        "3. Data Description\n",
        "4. Setup and Environment\n",
        "5. Data Loading\n",
        "6. Data Preparation\n",
        "7. Model Planning\n",
        "8. Model Building / Analysis\n",
        "9. Discussion & Interpretation\n",
        "10. Conclusion\n",
        "11. References\n",
        "12. Appendix"
      ]
    },
    {
      "metadata": {
        "id": "h6FSAiEmqn5Y"
      },
      "cell_type": "markdown",
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yAlW921_rRvk"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction"
      ],
      "metadata": {
        "id": "rNHFUNoMrZkD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem Statement / Research Question"
      ],
      "metadata": {
        "id": "gxlnArrBrm4I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predicting the overall quality of a clinic or hospital based on the location"
      ],
      "metadata": {
        "id": "8ELy7SqJK629"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Description"
      ],
      "metadata": {
        "id": "0C3kZi5HrrSk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 136,000+ unique healthcare locations, each with metadata such as geolocation, ratings, contact details, and images.\n",
        "\n",
        "- Doctor-to-location relationships, where each doctor may be linked to multiple clinic/hospital locations (up to 22).\n",
        "\n",
        "- City and province information, which is highly varied (1,511 unique cities) but shows hierarchical grouping.\n",
        "\n",
        "- Doctor location hours, providing structured scheduling data with attributes like day of week, opening/closing times, and timezone.\n",
        "\n",
        "- Despite the richness of the dataset, it suffers from high cardinality, nested structures, multi-level relationships, and significant sparsity in some fields (e.g., images, postal codes, ratings).\n",
        "\n",
        "- These issues make it difficult to efficiently perform:\n",
        "1. Data quality analysis\n",
        "2. Location search and ranking\n",
        "3. Provider attribution\n",
        "4. Geographic clustering\n",
        "5. Operational hours normalization\n",
        "6. Predictive modeling based on ratings or availability"
      ],
      "metadata": {
        "id": "iMQDxdsSK8YQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup and Environment"
      ],
      "metadata": {
        "id": "PV0iyLXurt7q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-cloud-storage"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mElIRgqfvDNX",
        "outputId": "23c77cee-9e94-489c-d7bd-b613042f8259"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.12/dist-packages (3.6.0)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.26.1 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage) (2.43.0)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=2.27.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage) (2.28.1)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0,>=2.4.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage) (2.5.0)\n",
            "Requirement already satisfied: google-resumable-media<3.0.0,>=2.7.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage) (2.8.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.22.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage) (2.32.4)\n",
            "Requirement already satisfied: google-crc32c<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage) (1.7.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3.0.0,>=2.27.0->google-cloud-storage) (1.72.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3.0.0,>=2.27.0->google-cloud-storage) (5.29.5)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3.0.0,>=2.27.0->google-cloud-storage) (1.26.1)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.26.1->google-cloud-storage) (6.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.26.1->google-cloud-storage) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.26.1->google-cloud-storage) (4.9.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.22.0->google-cloud-storage) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.22.0->google-cloud-storage) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.22.0->google-cloud-storage) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.22.0->google-cloud-storage) (2025.11.12)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.26.1->google-cloud-storage) (0.6.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import json\n",
        "import os\n",
        "from google.cloud import storage\n",
        "from io import BytesIO"
      ],
      "metadata": {
        "id": "Wd4ItUpruFe2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Loading"
      ],
      "metadata": {
        "id": "DMi7uYUhrx0F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Functions"
      ],
      "metadata": {
        "id": "kdcxnKu7vqbS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import storage\n",
        "import pandas as pd\n",
        "from io import BytesIO\n",
        "import os\n",
        "import json\n",
        "import requests\n",
        "import re # Import regex module for parsing HTML\n",
        "\n",
        "def list_public_bucket(bucket_name, course, project):\n",
        "    prefix = f\"{course}/Project {project}/\"\n",
        "\n",
        "    client = storage.Client.create_anonymous_client()\n",
        "    bucket = client.bucket(bucket_name)\n",
        "    blobs = client.list_blobs(bucket, prefix=prefix)\n",
        "    print(f\"Listing files in public bucket '{bucket_name}' under '{prefix}':\")\n",
        "    filenames = []\n",
        "    for blob in blobs:\n",
        "        print(blob.name)\n",
        "        filenames.append(blob.name)\n",
        "\n",
        "    return filenames\n",
        "\n",
        "def gdrive_file_to_dataframe(file_id: str, file_type: str):\n",
        "    \"\"\"\n",
        "    Downloads a file from Google Drive using its ID and returns a pandas DataFrame.\n",
        "    Handles Google Drive virus scan warnings by parsing the HTML form to get the\n",
        "    actual download URL.\n",
        "    \"\"\"\n",
        "    URL = \"https://docs.google.com/uc?export=download\"\n",
        "\n",
        "    session = requests.Session()\n",
        "    response = session.get(URL, params={'id': file_id}, stream=True)\n",
        "    response.raise_for_status() # Raise an HTTPError for bad responses (4xx or 5xx)\n",
        "\n",
        "    # Check if the response content is the virus scan warning HTML page\n",
        "    if \"Google Drive - Virus scan warning\" in response.text:\n",
        "        print(\"Google Drive virus scan warning detected. Attempting to bypass...\")\n",
        "        # Extract the download action URL and hidden input parameters from the HTML form\n",
        "        match = re.search(r'<form id=\"download-form\" action=\"([^\"]+)\" method=\"get\">', response.text)\n",
        "        if not match:\n",
        "            raise ValueError(\"Could not find download form in virus warning page.\")\n",
        "        download_action_url = match.group(1)\n",
        "\n",
        "        hidden_inputs = re.findall(r'<input type=\"hidden\" name=\"([^\"]+)\" value=\"([^\"]*)\">', response.text)\n",
        "        download_params = {name: value for name, value in hidden_inputs}\n",
        "\n",
        "        # Make the actual download request with the extracted parameters\n",
        "        final_response = session.get(download_action_url, params=download_params, stream=True)\n",
        "        final_response.raise_for_status()\n",
        "        data = BytesIO(final_response.content)\n",
        "    else:\n",
        "        # No virus warning, proceed with the initial response content\n",
        "        data = BytesIO(response.content)\n",
        "\n",
        "    df = None\n",
        "    if file_type == \"csv\":\n",
        "        df = pd.read_csv(data, engine='python', on_bad_lines='warn')\n",
        "    elif file_type in [\"xls\", \"xlsx\"]:\n",
        "        df = pd.read_excel(data)\n",
        "    elif file_type == \"parquet\":\n",
        "        df = pd.read_parquet(data)\n",
        "    elif file_type == \"json\":\n",
        "        text = data.read().decode(\"utf-8\")\n",
        "        json_obj = json.loads(text)\n",
        "        if isinstance(json_obj, list):\n",
        "            df = pd.DataFrame(json_obj)\n",
        "        elif isinstance(json_obj, dict):\n",
        "            df = pd.json_normalize(json_obj)\n",
        "        else:\n",
        "            raise ValueError(\"Unsupported JSON structure\")\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported file type: {file_type}\")\n",
        "\n",
        "    return df\n",
        "\n",
        "# Fetching the data from the provided Google Drive link\n",
        "try:\n",
        "    file_id_to_fetch = '1yJjVih68D_J4JON2LXMLGIh_FoeibwaG'\n",
        "    # Assuming the file type is CSV based on the filename provided\n",
        "    gdrive_df = gdrive_file_to_dataframe(file_id_to_fetch, 'csv')\n",
        "    print(\"Successfully fetched and loaded data from Google Drive into 'gdrive_df'. Head of the DataFrame:\")\n",
        "    print(gdrive_df.head())\n",
        "except Exception as e:\n",
        "    print(f\"Error fetching or loading data from Google Drive: {e}\")\n"
      ],
      "metadata": {
        "id": "1Wc3fjEBuFAz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1844011a-0a93-42d9-87a6-1ce61b77ab6e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Google Drive virus scan warning detected. Attempting to bypass...\n",
            "Successfully fetched and loaded data from Google Drive into 'gdrive_df'. Head of the DataFrame:\n",
            "                        _id                                           slug  \\\n",
            "0  647e89e399dca372f92a0d7c    3183031/Dr-Janan+S.-Sayyed-NEW+YORK-NY.html   \n",
            "1  647e89e499dca372f92a0d91      3345163/Dr-SHIRIN-PETERS-NEW+YORK-NY.html   \n",
            "2  647e89e499dca372f92a0db9  3081147/Dr-THOMAS+J.-MULHERN-New+York-NY.html   \n",
            "3  647e89e499dca372f92a0dba      3081144/Dr-ZINA-RUTKIN-GREAT+NECK-NY.html   \n",
            "4  647e89e499dca372f92a0dbd  3081128/Dr-JOHN+S.-CAVALLARO-Brooklyn-NY.html   \n",
            "\n",
            "                            created                          modified      id  \\\n",
            "0  2014-06-13T11:39:19.399618-04:00  2023-04-16T10:17:11.091386-04:00  870323   \n",
            "1  2014-06-13T10:53:51.310523-04:00  2022-11-15T15:19:02.430196-05:00  819737   \n",
            "2  2014-06-13T12:33:17.025883-04:00  2022-03-08T14:16:12.357691-05:00  939574   \n",
            "3  2014-06-13T12:33:17.131851-04:00  2022-03-08T14:16:12.357691-05:00  939577   \n",
            "4  2014-06-13T12:33:17.670698-04:00  2022-03-08T14:16:12.357691-05:00  939591   \n",
            "\n",
            "                                         facet_url              full_name  \\\n",
            "0            /best-doctors/?specialty=chiropractor    Dr. Janan S. Sayyed   \n",
            "1  /best-doctors/?specialty=internist-geriatrician      Dr. Shirin Peters   \n",
            "2            /best-doctors/?specialty=psychologist      Thomas J. Mulhern   \n",
            "3            /best-doctors/?specialty=psychologist            Zina Rutkin   \n",
            "4                 /best-doctors/?specialty=dentist  Dr. John S. Cavallaro   \n",
            "\n",
            "     full_name_specialty  location.id location.category  ...  \\\n",
            "0    Dr. Janan S. Sayyed       870221            clinic  ...   \n",
            "1      Dr. Shirin Peters       819635            clinic  ...   \n",
            "2      Thomas J. Mulhern       939475            clinic  ...   \n",
            "3            Zina Rutkin       939478            clinic  ...   \n",
            "4  Dr. John S. Cavallaro       939492            clinic  ...   \n",
            "\n",
            "  doctor_location_hours[8].location.url  \\\n",
            "0                                   NaN   \n",
            "1                                   NaN   \n",
            "2                                   NaN   \n",
            "3                                   NaN   \n",
            "4                                   NaN   \n",
            "\n",
            "  doctor_location_hours[0].location.geocode_address  \\\n",
            "0                                               NaN   \n",
            "1                                               NaN   \n",
            "2                                               NaN   \n",
            "3                                               NaN   \n",
            "4                                               NaN   \n",
            "\n",
            "   doctor_location_hours[1].location.geocode_address  \\\n",
            "0                                                NaN   \n",
            "1                                                NaN   \n",
            "2                                                NaN   \n",
            "3                                                NaN   \n",
            "4                                                NaN   \n",
            "\n",
            "   doctor_location_hours[2].location.geocode_address  \\\n",
            "0                                                NaN   \n",
            "1                                                NaN   \n",
            "2                                                NaN   \n",
            "3                                                NaN   \n",
            "4                                                NaN   \n",
            "\n",
            "  doctor_location_hours[3].location.geocode_address  \\\n",
            "0                                               NaN   \n",
            "1                                               NaN   \n",
            "2                                               NaN   \n",
            "3                                               NaN   \n",
            "4                                               NaN   \n",
            "\n",
            "   doctor_location_hours[4].location.geocode_address  \\\n",
            "0                                                NaN   \n",
            "1                                                NaN   \n",
            "2                                                NaN   \n",
            "3                                                NaN   \n",
            "4                                                NaN   \n",
            "\n",
            "  doctor_location_hours[5].location.geocode_address  \\\n",
            "0                                               NaN   \n",
            "1                                               NaN   \n",
            "2                                               NaN   \n",
            "3                                               NaN   \n",
            "4                                               NaN   \n",
            "\n",
            "  doctor_location_hours[6].location.geocode_address  \\\n",
            "0                                               NaN   \n",
            "1                                               NaN   \n",
            "2                                               NaN   \n",
            "3                                               NaN   \n",
            "4                                               NaN   \n",
            "\n",
            "  doctor_location_hours[7].location.geocode_address  \\\n",
            "0                                               NaN   \n",
            "1                                               NaN   \n",
            "2                                               NaN   \n",
            "3                                               NaN   \n",
            "4                                               NaN   \n",
            "\n",
            "  doctor_location_hours[8].location.geocode_address  \n",
            "0                                               NaN  \n",
            "1                                               NaN  \n",
            "2                                               NaN  \n",
            "3                                               NaN  \n",
            "4                                               NaN  \n",
            "\n",
            "[5 rows x 1611 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation"
      ],
      "metadata": {
        "id": "Q9toqCgWr0Op"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = gdrive_df\n",
        "\n",
        "print(\"Number of rows\", len(df))\n",
        "print(\"Number of columns\", len(df.columns))"
      ],
      "metadata": {
        "id": "eqLc8hNqrYxv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# datatypes available\n",
        "print(\"The datatypes available are:\")\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)\n",
        "print(df.dtypes)"
      ],
      "metadata": {
        "id": "edmnmaL5uEmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# similar naming columns\n",
        "pd.set_option('display.max_columns', None)\n",
        "df.columns = df.columns.str.lower().str.replace('_', '')\n",
        "\n",
        "list_cols= list(df.columns)\n",
        "print(\"The columns are:\")\n",
        "print(list_cols)"
      ],
      "metadata": {
        "id": "0sFvdjTHijaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These need not be changed:'id', 'slug', 'created', 'modified', 'id', 'faceturl', 'fullname', 'fullnamespecialty'"
      ],
      "metadata": {
        "id": "PRaUAi8fjRIq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Method 1: Feature engineering"
      ],
      "metadata": {
        "id": "8iPJOWt4PJae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Select usable columns\n",
        "# cols_to_keep = [\"_id\", \"full_name\", \"specialty_name\", \"location.city.name\",\"rating.average\", \"rating.helpfulness\", \"rating.punctuality\",\"rating.staff\", \"rating.count\"]\n",
        "\n",
        "# df_clean = df[cols_to_keep].copy()\n",
        "\n",
        "# # Rename columns to simpler names\n",
        "# df_clean = df_clean.rename(columns={\n",
        "#     \"location.city.name\": \"city\",\n",
        "#     \"rating.average\": \"rating_avg\",\n",
        "#     \"rating.helpfulness\": \"rating_help\",\n",
        "#     \"rating.punctuality\": \"rating_punctuality\",\n",
        "#     \"rating.staff\": \"rating_staff\",\n",
        "#     \"rating.count\": \"rating_count\"\n",
        "# })\n",
        "\n",
        "# # Convert numeric columns to proper numeric types\n",
        "# numeric_cols = [\n",
        "#     \"rating_avg\", \"rating_help\", \"rating_punctuality\",\n",
        "#     \"rating_staff\", \"rating_count\"\n",
        "# ]\n",
        "\n",
        "# for col in numeric_cols:\n",
        "#     df_clean[col] = pd.to_numeric(df_clean[col], errors=\"coerce\")\n",
        "\n",
        "# # Drop rows with no rating information\n",
        "# df_clean = df_clean.dropna(subset=[\"rating_avg\"])\n",
        "\n",
        "# # Before having this the rating avg and rating_help was 0's\n",
        "# df_clean = df_clean[df_clean[\"rating_count\"] > 0]\n",
        "# df_clean = df_clean[df_clean[\"rating_avg\"] > 0]\n",
        "\n",
        "# # Reset index\n",
        "# df_clean = df_clean.reset_index(drop=True)\n",
        "\n",
        "# df_clean.head() # this is to see the clean data"
      ],
      "metadata": {
        "id": "-upnmg83MW-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Method 2: Feature engineering"
      ],
      "metadata": {
        "id": "OdknHwF3PSXI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most columns share prefixes like:\n",
        "location.*\n",
        "images.*\n",
        "rating.*\n",
        "doctorlocations[n].*\n",
        "doctorlocationhours[n].*\n",
        "\n",
        "We can automatically group these"
      ],
      "metadata": {
        "id": "F3hkAf8ZPam6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def group_columns_by_prefix(df, sep='.'):\n",
        "    groups = {}\n",
        "    for col in df.columns:\n",
        "        prefix = col.split(sep)[0]\n",
        "        groups.setdefault(prefix, []).append(col)\n",
        "    return groups\n",
        "\n",
        "groups = group_columns_by_prefix(df)\n",
        "for g, cols in groups.items():\n",
        "    print(g, len(cols))\n"
      ],
      "metadata": {
        "id": "g7_QjwxfPRgu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "location_columns = [col for col in df.columns if 'location' in col]\n",
        "print(\"Columns with 'location' in their name:\")\n",
        "num=0\n",
        "for col in location_columns:\n",
        "    print(col)\n",
        "    num += 1\n",
        "print(\"Total number of columns with location:\", num)"
      ],
      "metadata": {
        "id": "TDgnN37oXafz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EDA\n",
        "\n",
        "#Identify all location related columns\n",
        "location_cols = [c for c in df.columns if \"location\" in c.lower()]\n",
        "print(\"Total location columns:\", len(location_cols))\n"
      ],
      "metadata": {
        "id": "LnrX-UPOLsxl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset contains extremely high-dimensional location metadata, hence we need to reduce it."
      ],
      "metadata": {
        "id": "cM-061umOlbU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After analysis the most required columns are the ones relating to location and rating, hence reducing to these columns."
      ],
      "metadata": {
        "id": "e_HXg8Yps4G5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecting Only Location columns and Rating columns\n",
        "rating_cols = [\n",
        "    \"location.rating.cleanliness\",\n",
        "    \"location.rating.facilities\",\n",
        "    \"location.rating.services\",\n",
        "    \"location.rating.average\",\n",
        "    \"location.rating.value\",\n",
        "    \"location.rating.count\",\n",
        "    \"location.rating.bestrating\"\n",
        "]\n",
        "\n",
        "# Filter columns that actually exist\n",
        "rating_cols = [c for c in rating_cols if c in df.columns]\n",
        "\n",
        "location_df = df[location_cols + rating_cols]\n",
        "print(\"Filtered df:\", location_df.shape)\n"
      ],
      "metadata": {
        "id": "IAPcI5sWOtwg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This filtered dataframe contains the filtered columns further required which has details on location and ratings"
      ],
      "metadata": {
        "id": "1nukovv0OtKb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing columns with very high number of missing values\n",
        "missing_percent = location_df.isnull().mean().sort_values(ascending=False)\n",
        "location_df = location_df.drop(columns=missing_percent[missing_percent > 0.80].index)\n",
        "\n",
        "print(\"After removing >80% missing:\", location_df.shape)\n"
      ],
      "metadata": {
        "id": "XLCrpNwvPKz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. The reason for removing this above 80% missing value columns was because the original dataset has hundreds of nested columns, in which many are empty.\n",
        "\n",
        "2. This reduction shows that most raw location columns are unusable, strengthening the case for creating an **aggregated representation**."
      ],
      "metadata": {
        "id": "xWW1f2b0Pl8b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. The **reason 1565 columns shrink to 89** is because\n",
        "\n",
        "The dataset contains:\n",
        "\n",
        "- 22 doctorlocations * ~70 repeated fields\n",
        "- 9 doctorlocationhours * ~60 repeated fields\n",
        "- city substructures * repeated image sizes (32*32, 70*70, 77*77, 165*165â€¦)\n",
        "- rating substructures\n",
        "- hundreds of rarely-filled, API-generated metadata columns\n",
        "- thousands of columns where 99% of values are empty"
      ],
      "metadata": {
        "id": "KWDUmjxOQTry"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. These were some of the **columns that are significant**:\n",
        "- location.rating.count\n",
        "- location.rating.bestrating\n",
        "- location.rating.cleanliness\n",
        "- location.rating.value\n",
        "- location.rating.count\n",
        "- location.rating.average\n",
        "- location.rating.bestrating\n",
        "- location.rating.services\n",
        "- location.rating.facilities"
      ],
      "metadata": {
        "id": "XPMmJ3rjQq5q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. We have **removed**:\n",
        "- Broken / unused nested keys\n",
        "- Empty image placeholders\n",
        "- Missing city-level fields\n",
        "- Duplicated doctorlocation structures\n",
        "- Mostly-null geocode fields"
      ],
      "metadata": {
        "id": "92IPYReNQ9as"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a copy of the final column\n",
        "location_core = location_df.copy()\n",
        "print(\"Final usable columns:\", location_core.shape)"
      ],
      "metadata": {
        "id": "mcgDCKqwtD90"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the final usable column"
      ],
      "metadata": {
        "id": "B0qWDQLXS20s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "location_core.columns"
      ],
      "metadata": {
        "id": "kslrkW7jVF17"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping the columns with images\n",
        "image_cols = ['location.images.autoxauto' , 'location.images.77x77' , 'location.images.100x100' , 'location.images.165x165' , 'location.images.70x70' , 'location.city.coverimages.253x83' , 'location.city.coverimages.autoxauto']\n",
        "final_df = location_core.drop(columns=image_cols)\n",
        "print(\"Final usable columns:\", final_df.shape)"
      ],
      "metadata": {
        "id": "knvhx2ywVNLy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fixing the column types\n",
        "final_df.dtypes"
      ],
      "metadata": {
        "id": "zX6BNo8PV5Ec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7M-lSHUFUq0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Method 3: Location and Rating"
      ],
      "metadata": {
        "id": "0EvYYEiNV9qW"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SV4IAkbG4kfD"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = gdrive_df\n",
        "\n",
        "#dropping columns with rating and has only location\n",
        "location_columns = [col for col in df.columns if 'location' in col]\n",
        "location_only_cols = [col for col in location_columns if 'rating' not in col]\n",
        "df_withlocation_norating = df[location_only_cols]\n",
        "print(\"Filtered df:\", df_withlocation_norating.shape)\n",
        "\n",
        "# removing image columns\n",
        "image_cols = [col for col in df_withlocation_norating.columns if 'images' in col]\n",
        "final_df = df_withlocation_norating.drop(columns=image_cols)\n",
        "print(\"Final usable columns:\", final_df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "QBdjzphT4qfj",
        "outputId": "431221a8-96f2-486a-9197-42e258890551"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'gdrive_df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1892058910.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgdrive_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#dropping columns with rating and has only location\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlocation_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'location'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlocation_only_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlocation_columns\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'rating'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'gdrive_df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for col in final_df.columns:\n",
        "  if final_df[col].dtype == 'float64':\n",
        "    print(col)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQ7N71JP6yjV",
        "outputId": "16a92eb1-31a2-4cdd-e430-ed99af1d1f76"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "location.id\n",
            "location.longitude\n",
            "location.latitude\n",
            "location.city.id\n",
            "location.city.province\n",
            "location.city_id\n",
            "doctor_locations[0].id\n",
            "doctor_locations[1].id\n",
            "doctor_locations[2].id\n",
            "doctor_locations[3].id\n",
            "doctor_locations[4].id\n",
            "doctor_locations[5].id\n",
            "doctor_locations[6].id\n",
            "doctor_locations[7].id\n",
            "doctor_locations[8].id\n",
            "doctor_locations[9].id\n",
            "doctor_locations[10].id\n",
            "doctor_locations[11].id\n",
            "doctor_locations[12].id\n",
            "doctor_locations[13].id\n",
            "doctor_locations[14].id\n",
            "doctor_locations[15].id\n",
            "doctor_locations[16].id\n",
            "doctor_locations[17].id\n",
            "doctor_locations[18].id\n",
            "doctor_locations[19].id\n",
            "doctor_locations[20].id\n",
            "doctor_locations[21].id\n",
            "doctor_locations[0].location.id\n",
            "doctor_locations[1].location.id\n",
            "doctor_locations[2].location.id\n",
            "doctor_locations[3].location.id\n",
            "doctor_locations[4].location.id\n",
            "doctor_locations[5].location.id\n",
            "doctor_locations[6].location.id\n",
            "doctor_locations[7].location.id\n",
            "doctor_locations[8].location.id\n",
            "doctor_locations[9].location.id\n",
            "doctor_locations[10].location.id\n",
            "doctor_locations[11].location.id\n",
            "doctor_locations[12].location.id\n",
            "doctor_locations[13].location.id\n",
            "doctor_locations[14].location.id\n",
            "doctor_locations[15].location.id\n",
            "doctor_locations[16].location.id\n",
            "doctor_locations[17].location.id\n",
            "doctor_locations[18].location.id\n",
            "doctor_locations[19].location.id\n",
            "doctor_locations[20].location.id\n",
            "doctor_locations[21].location.id\n",
            "doctor_locations[0].location.longitude\n",
            "doctor_locations[1].location.longitude\n",
            "doctor_locations[2].location.longitude\n",
            "doctor_locations[3].location.longitude\n",
            "doctor_locations[4].location.longitude\n",
            "doctor_locations[5].location.longitude\n",
            "doctor_locations[6].location.longitude\n",
            "doctor_locations[7].location.longitude\n",
            "doctor_locations[8].location.longitude\n",
            "doctor_locations[9].location.longitude\n",
            "doctor_locations[10].location.longitude\n",
            "doctor_locations[11].location.longitude\n",
            "doctor_locations[12].location.longitude\n",
            "doctor_locations[13].location.longitude\n",
            "doctor_locations[14].location.longitude\n",
            "doctor_locations[15].location.longitude\n",
            "doctor_locations[16].location.longitude\n",
            "doctor_locations[17].location.longitude\n",
            "doctor_locations[18].location.longitude\n",
            "doctor_locations[19].location.longitude\n",
            "doctor_locations[20].location.longitude\n",
            "doctor_locations[21].location.longitude\n",
            "doctor_locations[0].location.latitude\n",
            "doctor_locations[1].location.latitude\n",
            "doctor_locations[2].location.latitude\n",
            "doctor_locations[3].location.latitude\n",
            "doctor_locations[4].location.latitude\n",
            "doctor_locations[5].location.latitude\n",
            "doctor_locations[6].location.latitude\n",
            "doctor_locations[7].location.latitude\n",
            "doctor_locations[8].location.latitude\n",
            "doctor_locations[9].location.latitude\n",
            "doctor_locations[10].location.latitude\n",
            "doctor_locations[11].location.latitude\n",
            "doctor_locations[12].location.latitude\n",
            "doctor_locations[13].location.latitude\n",
            "doctor_locations[14].location.latitude\n",
            "doctor_locations[15].location.latitude\n",
            "doctor_locations[16].location.latitude\n",
            "doctor_locations[17].location.latitude\n",
            "doctor_locations[18].location.latitude\n",
            "doctor_locations[19].location.latitude\n",
            "doctor_locations[20].location.latitude\n",
            "doctor_locations[21].location.latitude\n",
            "doctor_locations[0].location.city.id\n",
            "doctor_locations[1].location.city.id\n",
            "doctor_locations[2].location.city.id\n",
            "doctor_locations[3].location.city.id\n",
            "doctor_locations[4].location.city.id\n",
            "doctor_locations[5].location.city.id\n",
            "doctor_locations[6].location.city.id\n",
            "doctor_locations[7].location.city.id\n",
            "doctor_locations[8].location.city.id\n",
            "doctor_locations[9].location.city.id\n",
            "doctor_locations[10].location.city.id\n",
            "doctor_locations[11].location.city.id\n",
            "doctor_locations[12].location.city.id\n",
            "doctor_locations[13].location.city.id\n",
            "doctor_locations[14].location.city.id\n",
            "doctor_locations[15].location.city.id\n",
            "doctor_locations[16].location.city.id\n",
            "doctor_locations[17].location.city.id\n",
            "doctor_locations[18].location.city.id\n",
            "doctor_locations[19].location.city.id\n",
            "doctor_locations[20].location.city.id\n",
            "doctor_locations[21].location.city.id\n",
            "doctor_locations[19].location.city.cover_image\n",
            "doctor_locations[20].location.city.cover_image\n",
            "doctor_locations[0].location.city.province\n",
            "doctor_locations[1].location.city.province\n",
            "doctor_locations[2].location.city.province\n",
            "doctor_locations[3].location.city.province\n",
            "doctor_locations[4].location.city.province\n",
            "doctor_locations[5].location.city.province\n",
            "doctor_locations[6].location.city.province\n",
            "doctor_locations[7].location.city.province\n",
            "doctor_locations[8].location.city.province\n",
            "doctor_locations[9].location.city.province\n",
            "doctor_locations[10].location.city.province\n",
            "doctor_locations[11].location.city.province\n",
            "doctor_locations[12].location.city.province\n",
            "doctor_locations[13].location.city.province\n",
            "doctor_locations[14].location.city.province\n",
            "doctor_locations[15].location.city.province\n",
            "doctor_locations[16].location.city.province\n",
            "doctor_locations[17].location.city.province\n",
            "doctor_locations[18].location.city.province\n",
            "doctor_locations[19].location.city.province\n",
            "doctor_locations[20].location.city.province\n",
            "doctor_locations[21].location.city.province\n",
            "doctor_locations[20].location.suite\n",
            "doctor_locations[21].location.suite\n",
            "doctor_locations[2].location.postal_code\n",
            "doctor_locations[3].location.postal_code\n",
            "doctor_locations[4].location.postal_code\n",
            "doctor_locations[5].location.postal_code\n",
            "doctor_locations[6].location.postal_code\n",
            "doctor_locations[7].location.postal_code\n",
            "doctor_locations[8].location.postal_code\n",
            "doctor_locations[9].location.postal_code\n",
            "doctor_locations[10].location.postal_code\n",
            "doctor_locations[11].location.postal_code\n",
            "doctor_locations[12].location.postal_code\n",
            "doctor_locations[13].location.postal_code\n",
            "doctor_locations[14].location.postal_code\n",
            "doctor_locations[15].location.postal_code\n",
            "doctor_locations[16].location.postal_code\n",
            "doctor_locations[17].location.postal_code\n",
            "doctor_locations[18].location.postal_code\n",
            "doctor_locations[19].location.postal_code\n",
            "doctor_locations[20].location.postal_code\n",
            "doctor_locations[21].location.postal_code\n",
            "doctor_locations[0].location.city_id\n",
            "doctor_locations[1].location.city_id\n",
            "doctor_locations[2].location.city_id\n",
            "doctor_locations[3].location.city_id\n",
            "doctor_locations[4].location.city_id\n",
            "doctor_locations[5].location.city_id\n",
            "doctor_locations[6].location.city_id\n",
            "doctor_locations[7].location.city_id\n",
            "doctor_locations[8].location.city_id\n",
            "doctor_locations[9].location.city_id\n",
            "doctor_locations[10].location.city_id\n",
            "doctor_locations[11].location.city_id\n",
            "doctor_locations[12].location.city_id\n",
            "doctor_locations[13].location.city_id\n",
            "doctor_locations[14].location.city_id\n",
            "doctor_locations[15].location.city_id\n",
            "doctor_locations[16].location.city_id\n",
            "doctor_locations[17].location.city_id\n",
            "doctor_locations[18].location.city_id\n",
            "doctor_locations[19].location.city_id\n",
            "doctor_locations[20].location.city_id\n",
            "doctor_locations[21].location.city_id\n",
            "doctor_locations[20].location.phone_number\n",
            "doctor_locations[21].location.phone_number\n",
            "doctor_locations[19].location.website\n",
            "doctor_locations[20].location.website\n",
            "doctor_locations[21].location.website\n",
            "doctor_locations[9].location.image\n",
            "doctor_locations[10].location.image\n",
            "doctor_locations[12].location.image\n",
            "doctor_locations[13].location.image\n",
            "doctor_locations[14].location.image\n",
            "doctor_locations[15].location.image\n",
            "doctor_locations[17].location.image\n",
            "doctor_locations[18].location.image\n",
            "doctor_locations[19].location.image\n",
            "doctor_locations[20].location.image\n",
            "doctor_locations[21].location.image\n",
            "doctor_locations[0].location_id\n",
            "doctor_locations[1].location_id\n",
            "doctor_locations[2].location_id\n",
            "doctor_locations[3].location_id\n",
            "doctor_locations[4].location_id\n",
            "doctor_locations[5].location_id\n",
            "doctor_locations[6].location_id\n",
            "doctor_locations[7].location_id\n",
            "doctor_locations[8].location_id\n",
            "doctor_locations[9].location_id\n",
            "doctor_locations[10].location_id\n",
            "doctor_locations[11].location_id\n",
            "doctor_locations[12].location_id\n",
            "doctor_locations[13].location_id\n",
            "doctor_locations[14].location_id\n",
            "doctor_locations[15].location_id\n",
            "doctor_locations[16].location_id\n",
            "doctor_locations[17].location_id\n",
            "doctor_locations[18].location_id\n",
            "doctor_locations[19].location_id\n",
            "doctor_locations[20].location_id\n",
            "doctor_locations[21].location_id\n",
            "doctor_location_hours[0].id\n",
            "doctor_location_hours[1].id\n",
            "doctor_location_hours[2].id\n",
            "doctor_location_hours[3].id\n",
            "doctor_location_hours[4].id\n",
            "doctor_location_hours[5].id\n",
            "doctor_location_hours[6].id\n",
            "doctor_location_hours[7].id\n",
            "doctor_location_hours[8].id\n",
            "doctor_location_hours[0].day_number\n",
            "doctor_location_hours[1].day_number\n",
            "doctor_location_hours[2].day_number\n",
            "doctor_location_hours[3].day_number\n",
            "doctor_location_hours[4].day_number\n",
            "doctor_location_hours[5].day_number\n",
            "doctor_location_hours[6].day_number\n",
            "doctor_location_hours[7].day_number\n",
            "doctor_location_hours[8].day_number\n",
            "doctor_location_hours[0].location.id\n",
            "doctor_location_hours[1].location.id\n",
            "doctor_location_hours[2].location.id\n",
            "doctor_location_hours[3].location.id\n",
            "doctor_location_hours[4].location.id\n",
            "doctor_location_hours[5].location.id\n",
            "doctor_location_hours[6].location.id\n",
            "doctor_location_hours[7].location.id\n",
            "doctor_location_hours[8].location.id\n",
            "doctor_location_hours[0].location.longitude\n",
            "doctor_location_hours[1].location.longitude\n",
            "doctor_location_hours[2].location.longitude\n",
            "doctor_location_hours[3].location.longitude\n",
            "doctor_location_hours[4].location.longitude\n",
            "doctor_location_hours[5].location.longitude\n",
            "doctor_location_hours[6].location.longitude\n",
            "doctor_location_hours[7].location.longitude\n",
            "doctor_location_hours[8].location.longitude\n",
            "doctor_location_hours[0].location.latitude\n",
            "doctor_location_hours[1].location.latitude\n",
            "doctor_location_hours[2].location.latitude\n",
            "doctor_location_hours[3].location.latitude\n",
            "doctor_location_hours[4].location.latitude\n",
            "doctor_location_hours[5].location.latitude\n",
            "doctor_location_hours[6].location.latitude\n",
            "doctor_location_hours[7].location.latitude\n",
            "doctor_location_hours[8].location.latitude\n",
            "doctor_location_hours[0].location.city.id\n",
            "doctor_location_hours[1].location.city.id\n",
            "doctor_location_hours[2].location.city.id\n",
            "doctor_location_hours[3].location.city.id\n",
            "doctor_location_hours[4].location.city.id\n",
            "doctor_location_hours[5].location.city.id\n",
            "doctor_location_hours[6].location.city.id\n",
            "doctor_location_hours[7].location.city.id\n",
            "doctor_location_hours[8].location.city.id\n",
            "doctor_location_hours[7].location.city.cover_image\n",
            "doctor_location_hours[8].location.city.cover_image\n",
            "doctor_location_hours[0].location.city.province\n",
            "doctor_location_hours[1].location.city.province\n",
            "doctor_location_hours[2].location.city.province\n",
            "doctor_location_hours[3].location.city.province\n",
            "doctor_location_hours[4].location.city.province\n",
            "doctor_location_hours[5].location.city.province\n",
            "doctor_location_hours[6].location.city.province\n",
            "doctor_location_hours[7].location.city.province\n",
            "doctor_location_hours[8].location.city.province\n",
            "doctor_location_hours[0].location.city_id\n",
            "doctor_location_hours[1].location.city_id\n",
            "doctor_location_hours[2].location.city_id\n",
            "doctor_location_hours[3].location.city_id\n",
            "doctor_location_hours[4].location.city_id\n",
            "doctor_location_hours[5].location.city_id\n",
            "doctor_location_hours[6].location.city_id\n",
            "doctor_location_hours[7].location.city_id\n",
            "doctor_location_hours[8].location.city_id\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ZWhzCGigWuRE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Planning"
      ],
      "metadata": {
        "id": "2LakOsEXr3lT"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6OppN2NguEMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Vl5RPihiuD9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model building / Analysis"
      ],
      "metadata": {
        "id": "4CjKZrjUr5jE"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cOzrfMmPuDTf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hRdii9o7uCw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Discussion and Results"
      ],
      "metadata": {
        "id": "Fw_hs8cur9ep"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "fMIDNj9YuAbo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion"
      ],
      "metadata": {
        "id": "fstKat9EsCOz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "9_S9Jo3tt9y3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## References"
      ],
      "metadata": {
        "id": "wN9Uya8asFaR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Barber, David. Bayesian Reasoning and Machine Learning. Cambridge University Press, 2012.\n",
        "2. Aste, Tomaso, Paola Cerchiello, and Roberta Scaramozzino. \"Information-Theoretic Causality Detection between Financial and Sentiment Data.\"Entropy, vol. 24, no. 6, 2022, pp. 1â€“18. DOI:10.3390/e24060774.\n",
        "3. Metz, Cade. \"Microsoft Puts OpenAIâ€™s Sam Altman in Charge of New Advanced AI Research Team.\"\n",
        "The New York Times, 20 Nov. 2023, www.nytimes.com/2023/11/20/technology/openai-microsoft-altman.html"
      ],
      "metadata": {
        "id": "iqLZY_rAt-TW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Appendix"
      ],
      "metadata": {
        "id": "ZT5TPWb9sHws"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vIxXm5Dlt_Uf"
      }
    }
  ]
}